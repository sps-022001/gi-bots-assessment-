# -*- coding: utf-8 -*-
"""final machine learing assessment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NUmbm2F62j9SA1FZ6sA5zV435oEYERLg
"""

import numpy as np
import pandas as pd

train_df=pd.read_csv('/content/train.csv')
test_df=pd.read_csv('/content/test.csv')
train_target_df=pd.read_csv('/content/trainLabels.csv')

train_df

test_df

train_target_df

test_df.columns=['id',
                 'x1','x2','x3','x4','x5','x6','x7','x8','x9','x10',
                 'x11','x12','x13','x14','x15','x16','x17','x18','x19','x20',
                 'x21','x22','x23','x24','x25','x26','x27','x28','x29','x30',
                 'x31','x32','x33','x34','x35','x36','x37','x38','x39','x40',
                 'x41','x42','x43','x44','x45','x46','x47','x48','x49','x50',
                 'x51','x52','x53','x54','x55','x56','x57','x58','x59','x60',
                 'x61','x62','x63','x64','x65','x66','x67','x68','x69','x70',
                 'x71','x72','x73','x74','x75','x76','x77','x78','x79','x80',
                 'x81','x82','x83','x84','x85','x86','x87','x88','x89','x90',
                 'x91','x92','x93','x94','x95','x96','x97','x98','x99','x100',
                 'x101','x102','x103','x104','x105','x106','x107','x108','x109','x110',
                 'x111','x112','x113','x114','x115','x116','x117','x118','x119','x120',
                 'x121','x122','x123','x124','x125','x126','x127','x128','x129','x130',
                 'x131','x132','x133','x134','x135','x136','x137','x138','x139','x140',
                 'x141','x142','x143','x144','x145']

test_df

train_df.info()
print(" ")
test_df.info()
print(" ")
train_target_df.info()

numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
numeric_columns=train_df.select_dtypes(include=numerics).columns.to_list()
len(numeric_columns)

object_columns=train_df.select_dtypes(include=object).columns
len(object_columns)

train_df[object_columns]=train_df[object_columns].astype(str)
test_df[object_columns]=test_df[object_columns].astype(str)

train_df[object_columns].info()

test_df[object_columns].info()

boolean_columns=[]
alphanumeric_columns=[]
for col in object_columns:
    if train_df[col][0].isupper()==True:
        boolean_columns.append(col)
    else:
        alphanumeric_columns.append(col)

alphanumeric_columns

boolean_columns

train_df[boolean_columns]=train_df[boolean_columns].astype('category')
test_df[boolean_columns]=test_df[boolean_columns].astype('category')

train_df.info()
print("")
test_df.info()

train_string=train_df[alphanumeric_columns]
test_string=test_df[alphanumeric_columns]

train_string

test_string

from sklearn.feature_extraction.text import CountVectorizer

for col in alphanumeric_columns:
    vectorizer = CountVectorizer()
    vectorizer.fit(train_string[col])
    train_df[col] = vectorizer.transform(train_string[col]).toarray()
    test_df[col] = vectorizer.transform(test_string[col]).toarray()

train_df

test_df

from sklearn.impute import SimpleImputer
num_imputer=SimpleImputer(strategy='mean')
obj_imputer=SimpleImputer(strategy='most_frequent')
num_imputer.fit(train_df[numeric_columns])

train_df[numeric_columns]=num_imputer.transform(train_df[numeric_columns])
num_imputer.fit(test_df[numeric_columns])
test_df[numeric_columns]=num_imputer.transform(test_df[numeric_columns])

train_df

test_df

train_df[numeric_columns].isna().sum()

test_df[numeric_columns].isna().sum()

train_df[boolean_columns]

test_df[boolean_columns]

for col in boolean_columns:
    train_df[col].replace({'YES':1, 'NO':0,'nan':None},inplace=True)
    test_df[col].replace({'YES':1, 'NO':0,'nan':None},inplace=True)

obj_imputer.fit(train_df[boolean_columns])

train_df[boolean_columns]=obj_imputer.transform(train_df[boolean_columns])

obj_imputer.fit(test_df[boolean_columns])

test_df[boolean_columns]=obj_imputer.transform(test_df[boolean_columns])

train_df[boolean_columns]

test_df[boolean_columns]

train_df[boolean_columns]=train_df[boolean_columns].astype('int')
test_df[boolean_columns]=test_df[boolean_columns].astype('int')

train_df[numeric_columns].info()

test_df[numeric_columns].info()

#training

X_train=train_df
X_test=test_df
Y_train=train_target_df.loc[:9998,'y1':]

X_train.shape

X_test.shape

Y_train.shape

!pip install scikit-multilearn

from skmultilearn.problem_transform import BinaryRelevance
from sklearn.naive_bayes import GaussianNB

# initialize binary relevance multi-label classifier
# with a gaussian naive bayes base classifier
classifier = BinaryRelevance(classifier=GaussianNB())

# train
classifier.fit(X_train.values,Y_train.values)

# predict
predictions = classifier.predict(X_test.values)

predictions

prediction_arr=predictions.toarray()

test_df['id'] = test_df['id'].astype(int)

test_df.id

target=[]
for num in test_df.id:
    for i in range(1,34):
        target.append(str(num)+'_y'+str(i))

len(target)

final_df=pd.DataFrame(target,columns=['id_label'])

final_df

prediction_list=[]
for i in range(len(prediction_arr)):
    prediction_list.extend(prediction_arr.tolist()[i])

pred_df=pd.DataFrame(prediction_list,columns=['pred'])

test_prediction_df=pd.concat([final_df,pred_df],axis=1)

test_prediction_df

test_prediction_df.to_csv('output.csv',index=None)